# 从 Tool 开始：让大模型自动调工具读文件 - 总结

## 一、为什么需要 Tool

- 普通聊天里大模型只能「告诉你怎么做」，不能替你执行（读写文件、执行命令等）。
- Cursor 能直接创建项目、写文件、装依赖、跑起来，是因为给 Agent 开发了 **Tool**，由模型在对话中决定何时调用。
- 常见 Tool：读文件、写文件、读目录、建目录、执行命令等。本节以「读文件」为例入门。

## 二、准备工作

**1. 大模型与 API**

- 示例用阿里千问（登录有免费 token 额度），其他模型同理。调用时需：`modelName`、`apiKey`、`baseURL`（见下方）。

**在百炼控制台获取并设置 API Key：**

1. 打开 [阿里云百炼控制台 - API 密钥](https://bailian.console.aliyun.com/cn-beijing/?tab=api#/api)（需先登录阿里云账号）。
2. 在「API-KEY 管理」或「API 密钥」页中，点击「创建 API-KEY」或使用已有密钥。
3. 创建后复制生成的 **API Key**（形如 `sk-xxx`），妥善保存；若泄露可在控制台删除该 Key 后重新创建。
4. 在项目根目录的 `.env` 中设置：
   - `OPENAI_API_KEY=你复制的 API Key`
   - `OPENAI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1`（千问兼容 OpenAI 的接口地址）
   - `MODEL_NAME=qwen-coder-turbo`（编码场景可选用该模型；控制台「模型广场」中也可查看其他模型名称）。
5. 代码中通过 dotenv 读取上述环境变量，不要将 API Key 写死在源码里。

**2. 项目与依赖**

- 创建项目后安装：`@langchain/openai`、`dotenv`；开发 Tool 时还需 `@langchain/core`、`zod`。
- 用 **.env** 存 `OPENAI_API_KEY`、`OPENAI_BASE_URL`、`MODEL_NAME`，代码里用 `import './loadEnv.mjs'` 读取，不要写死 API Key。
- 将 `.env` 加入 **.gitignore**，私密信息不提交 Git。

## 三、开发 read_file Tool

- 使用 LangChain 的 **tool( 执行函数, 元数据 )**：
  - **执行函数**：接收参数（如 `{ filePath }`），读文件并返回内容字符串。
  - **元数据**：`name`（工具名）、`description`（给模型看的说明）、`schema`（参数格式，用 **zod** 声明，如 `z.object({ filePath: z.string() })`）。
- 用 **model.bindTools(tools)** 把工具绑到模型，模型在回复时可能返回 **tool_calls**（要调用的工具名和参数），而不是直接给最终答案。

## 四、四种 Message

| 类型 | 含义 |
| --- | --- |
| **SystemMessage** | 设定 AI 身份、能力、行为规范（如：你是代码助手，可以读文件并解释代码）。 |
| **HumanMessage** | 用户输入。 |
| **AIMessage** | 模型回复；若模型决定调工具，会带 `tool_calls` 数组。 |
| **ToolMessage** | 工具执行结果，回传给模型；需带 **tool_call_id** 与对应的 tool call 关联。 |

用 SystemMessage 说明「可用 read_file 工具、何时调用、如何回答」，用 HumanMessage 发用户请求（如「请读取 src/xxx.mjs 并解释」）。

## 五、Tool 调用循环

- 第一次 **modelWithTools.invoke(messages)** 后，若 `response.tool_calls?.length > 0`，说明模型要求执行工具，而不是直接给最终答案。
- 循环逻辑：
  1. 根据 `response.tool_calls` 在 `tools` 里找到对应工具，用 **tool.invoke(toolCall.args)** 执行。
  2. 将每个结果封装成 **ToolMessage**（`content` = 工具返回值，`tool_call_id` = 对应 `toolCall.id`）。
  3. 把本轮的 **response（AIMessage）** 和这些 **ToolMessage** 追加进 **messages**，再 **invoke** 一次。
  4. 重复直到 `response` 不再包含 `tool_calls`，此时 `response.content` 即为最终回答。

这样模型就能「先发 tool_calls → 你执行工具 → 回传 ToolMessage → 模型再基于文件内容回答」。

## 六、总结

- 用 **.env + dotenv** 管理 API 配置，**.gitignore** 忽略 .env。
- **Tool** = 执行函数 + name/description/schema（zod）；**model.bindTools(tools)** 后模型可返回 tool_calls。
- 四种消息：System（设定）、Human（用户）、AI（含 tool_calls）、Tool（工具结果，带 tool_call_id）。
- 实现「检测 tool_calls → 执行工具 → 追加 ToolMessage → 再 invoke」的循环，即可让大模型通过工具读文件并解释代码；同理可扩展写文件、执行命令等，向「简易版 Cursor」迈进。
